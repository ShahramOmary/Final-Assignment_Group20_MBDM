{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "from ema_workbench import load_results\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "from ema_workbench.em_framework.optimization import (HyperVolume, EpsilonProgress)\n",
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "from ema_workbench import (Model, MultiprocessingEvaluator, SequentialEvaluator,\n",
    "                           Constraint, Policy, Scenario)\n",
    "\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, CategoricalParameter,\n",
    "                           ScalarOutcome, IntegerParameter, RealParameter)\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "\n",
    "\n",
    "def sum_over(*args):\n",
    "    return sum(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import (Model, MultiprocessingEvaluator, Policy, Scenario)\n",
    "from ema_workbench.em_framework.evaluators import perform_experiments\n",
    "from ema_workbench.em_framework.samplers import sample_uncertainties\n",
    "from ema_workbench.util import ema_logging\n",
    "import time\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "#choose problem formulation\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalParameter('discount rate 0', [0, 1, 2, 3])\n",
      "CategoricalParameter('discount rate 1', [0, 1, 2, 3])\n",
      "CategoricalParameter('discount rate 2', [0, 1, 2, 3])\n",
      "IntegerParameter('A.0_ID flood wave shape', 0, 132, resolution=None, default=None, variable_name=['A.0_ID flood wave shape'], pff=False)\n",
      "RealParameter('A.1_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.1_Bmax'], pff=False)\n",
      "RealParameter('A.1_pfail', 0, 1, resolution=None, default=None, variable_name=['A.1_pfail'], pff=False)\n",
      "CategoricalParameter('A.1_Brate', [0, 1, 2])\n",
      "RealParameter('A.2_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.2_Bmax'], pff=False)\n",
      "RealParameter('A.2_pfail', 0, 1, resolution=None, default=None, variable_name=['A.2_pfail'], pff=False)\n",
      "CategoricalParameter('A.2_Brate', [0, 1, 2])\n",
      "RealParameter('A.3_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.3_Bmax'], pff=False)\n",
      "RealParameter('A.3_pfail', 0, 1, resolution=None, default=None, variable_name=['A.3_pfail'], pff=False)\n",
      "CategoricalParameter('A.3_Brate', [0, 1, 2])\n",
      "RealParameter('A.4_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.4_Bmax'], pff=False)\n",
      "RealParameter('A.4_pfail', 0, 1, resolution=None, default=None, variable_name=['A.4_pfail'], pff=False)\n",
      "CategoricalParameter('A.4_Brate', [0, 1, 2])\n",
      "RealParameter('A.5_Bmax', 30, 350, resolution=None, default=None, variable_name=['A.5_Bmax'], pff=False)\n",
      "RealParameter('A.5_pfail', 0, 1, resolution=None, default=None, variable_name=['A.5_pfail'], pff=False)\n",
      "CategoricalParameter('A.5_Brate', [0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#enlisting uncertainties, their types (RealParameter/IntegerParameter/CategoricalParameter),\n",
    "#lower boundary, and upper boundary\n",
    "for unc in dike_model.uncertainties:\n",
    "    print(repr(unc))\n",
    "    \n",
    "uncertainties = dike_model.uncertainties\n",
    "\n",
    "import copy\n",
    "uncertainties = copy.deepcopy(dike_model.uncertainties)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IntegerParameter('0_RfR 0', 0, 1, resolution=None, default=None, variable_name=['0_RfR 0'], pff=False)\n",
      "IntegerParameter('0_RfR 1', 0, 1, resolution=None, default=None, variable_name=['0_RfR 1'], pff=False)\n",
      "IntegerParameter('0_RfR 2', 0, 1, resolution=None, default=None, variable_name=['0_RfR 2'], pff=False)\n",
      "IntegerParameter('1_RfR 0', 0, 1, resolution=None, default=None, variable_name=['1_RfR 0'], pff=False)\n",
      "IntegerParameter('1_RfR 1', 0, 1, resolution=None, default=None, variable_name=['1_RfR 1'], pff=False)\n",
      "IntegerParameter('1_RfR 2', 0, 1, resolution=None, default=None, variable_name=['1_RfR 2'], pff=False)\n",
      "IntegerParameter('2_RfR 0', 0, 1, resolution=None, default=None, variable_name=['2_RfR 0'], pff=False)\n",
      "IntegerParameter('2_RfR 1', 0, 1, resolution=None, default=None, variable_name=['2_RfR 1'], pff=False)\n",
      "IntegerParameter('2_RfR 2', 0, 1, resolution=None, default=None, variable_name=['2_RfR 2'], pff=False)\n",
      "IntegerParameter('3_RfR 0', 0, 1, resolution=None, default=None, variable_name=['3_RfR 0'], pff=False)\n",
      "IntegerParameter('3_RfR 1', 0, 1, resolution=None, default=None, variable_name=['3_RfR 1'], pff=False)\n",
      "IntegerParameter('3_RfR 2', 0, 1, resolution=None, default=None, variable_name=['3_RfR 2'], pff=False)\n",
      "IntegerParameter('4_RfR 0', 0, 1, resolution=None, default=None, variable_name=['4_RfR 0'], pff=False)\n",
      "IntegerParameter('4_RfR 1', 0, 1, resolution=None, default=None, variable_name=['4_RfR 1'], pff=False)\n",
      "IntegerParameter('4_RfR 2', 0, 1, resolution=None, default=None, variable_name=['4_RfR 2'], pff=False)\n",
      "IntegerParameter('EWS_DaysToThreat', 0, 4, resolution=None, default=None, variable_name=['EWS_DaysToThreat'], pff=False)\n",
      "IntegerParameter('A.1_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.1_DikeIncrease 0'], pff=False)\n",
      "IntegerParameter('A.1_DikeIncrease 1', 0, 10, resolution=None, default=None, variable_name=['A.1_DikeIncrease 1'], pff=False)\n",
      "IntegerParameter('A.1_DikeIncrease 2', 0, 10, resolution=None, default=None, variable_name=['A.1_DikeIncrease 2'], pff=False)\n",
      "IntegerParameter('A.2_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.2_DikeIncrease 0'], pff=False)\n",
      "IntegerParameter('A.2_DikeIncrease 1', 0, 10, resolution=None, default=None, variable_name=['A.2_DikeIncrease 1'], pff=False)\n",
      "IntegerParameter('A.2_DikeIncrease 2', 0, 10, resolution=None, default=None, variable_name=['A.2_DikeIncrease 2'], pff=False)\n",
      "IntegerParameter('A.3_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.3_DikeIncrease 0'], pff=False)\n",
      "IntegerParameter('A.3_DikeIncrease 1', 0, 10, resolution=None, default=None, variable_name=['A.3_DikeIncrease 1'], pff=False)\n",
      "IntegerParameter('A.3_DikeIncrease 2', 0, 10, resolution=None, default=None, variable_name=['A.3_DikeIncrease 2'], pff=False)\n",
      "IntegerParameter('A.4_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.4_DikeIncrease 0'], pff=False)\n",
      "IntegerParameter('A.4_DikeIncrease 1', 0, 10, resolution=None, default=None, variable_name=['A.4_DikeIncrease 1'], pff=False)\n",
      "IntegerParameter('A.4_DikeIncrease 2', 0, 10, resolution=None, default=None, variable_name=['A.4_DikeIncrease 2'], pff=False)\n",
      "IntegerParameter('A.5_DikeIncrease 0', 0, 10, resolution=None, default=None, variable_name=['A.5_DikeIncrease 0'], pff=False)\n",
      "IntegerParameter('A.5_DikeIncrease 1', 0, 10, resolution=None, default=None, variable_name=['A.5_DikeIncrease 1'], pff=False)\n",
      "IntegerParameter('A.5_DikeIncrease 2', 0, 10, resolution=None, default=None, variable_name=['A.5_DikeIncrease 2'], pff=False)\n"
     ]
    }
   ],
   "source": [
    "#enlisting policy levers, their types (RealParameter/IntegerParameter),\n",
    "#lower boundary, and upper boundary\n",
    "for policy in dike_model.levers:\n",
    "    print(repr(policy))\n",
    "    \n",
    "levers = dike_model.levers \n",
    "\n",
    "import copy\n",
    "levers = copy.deepcopy(dike_model.levers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #enlisting outcomes\n",
    "# for outcome in dike_model.outcomes:\n",
    "#     print(repr(outcome))\n",
    "    \n",
    "# specify outcomes\n",
    "# note how we need to explicitely indicate the direction\n",
    "dike_model.outcomes = [ScalarOutcome('Expected Annual Damage', kind=ScalarOutcome.MINIMIZE),\n",
    "                  ScalarOutcome('Total Investment Costs', kind=ScalarOutcome.MINIMIZE),\n",
    "                  ScalarOutcome('Expected Number of Deaths', kind=ScalarOutcome.MINIMIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] pool started with 8 workers\n",
      "  0%|                                                 | 0/5000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#--- Search for candidate solutions through optimization\n",
    "from ema_workbench.em_framework.optimization import (ArchiveLogger,\n",
    "                                                     EpsilonProgress)\n",
    "convergence_metrics  = [EpsilonProgress()]\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.optimize(nfe=5000, searchover='levers',\n",
    "                                 convergence=convergence_metrics,\n",
    "                                 epsilons=[0.01,]*len(dike_model.outcomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize(scenario, nfe, model, converge_metrics, epsilons):\n",
    "#     #with SequentialEvaluator(model) as evaluator:\n",
    "#     with MultiprocessingEvaluator(model) as evaluator:\n",
    "#         results, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "#                                      convergence=convergence_metrics,\n",
    "#                                      epsilons=epsilons,\n",
    "#                                      reference=scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the base case results\n",
    "# experiments, outcomes = load_results('results/4000  base scenarios policy pf 1.tar.gz') \n",
    "# outcomes_df = pd.DataFrame.from_dict(outcomes)\n",
    "\n",
    "# Assuming you have a CSV file called 'input.csv'\n",
    "relevant_scenarios = pd.read_csv('results/relevant scenarios.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_scenarios = relevant_scenarios.loc[:,:'discount rate 2']\n",
    "scenarios =  [Scenario(f\"{index}\", **row) for index, row in relevant_scenarios.iterrows()]\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(scenario)\n",
    "    \n",
    "df_scenarios = pd.DataFrame(scenarios) \n",
    "df_scenarios.to_csv(\"data/scenarios_test.csv\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#specify uncertainties\n",
    "dike_model.uncertainties = [IntegerParameter('A.0_ID flood wave shape', 0, 133),\n",
    "                   RealParameter('A.1_Bmax', 30,350),\n",
    "                   CategoricalParameter('A.1_Brate',(0.9,1.5,1000)),\n",
    "                   RealParameter('A.1_pfail',0,1),\n",
    "                   RealParameter('A.2_Bmax', 30,350),\n",
    "                   CategoricalParameter('A.2_Brate',(0.9,1.5,1000)),\n",
    "                   RealParameter('A.2_pfail',0,1),\n",
    "                   RealParameter('A.3_Bmax', 30,350),\n",
    "                   CategoricalParameter('A.3_Brate',(0.9,1.5,1000)),\n",
    "                   RealParameter('A.3_pfail',0,1),\n",
    "                   RealParameter('A.4_Bmax', 30,350),\n",
    "                   CategoricalParameter('A.4_Brate',(0.9,1.5,1000)),\n",
    "                   RealParameter('A.4_pfail',0,1),\n",
    "                   RealParameter('A.5_Bmax', 30,350),\n",
    "                   CategoricalParameter('A.5_Brate',(0.9,1.5,1000)),\n",
    "                   RealParameter('A.5_pfail',0,1),\n",
    "                   CategoricalParameter('discount rate 1',(1.5,2.5,3.5,4.5)),\n",
    "                   CategoricalParameter('discount rate 2',(1.5,2.5,3.5,4.5))]\n",
    "\n",
    "dike_model.levers = [IntegerParameter('A.1_DikeIncrease',0,10),\n",
    "                     IntegerParameter('A.2_DikeIncrease',0,10),\n",
    "                     IntegerParameter('A.3_DikeIncrease',0,10),\n",
    "                     IntegerParameter('A.4_DikeIncrease',0,10),\n",
    "                     IntegerParameter('A.5_DikeIncrease',0,2), #capped this variable to test if the model uses these specified levers\n",
    "                     IntegerParameter('1_RfR 0',0,1),\n",
    "                     IntegerParameter('2_RfR 0',0,1),\n",
    "                     IntegerParameter('3_RfR 0',0,1),\n",
    "                     IntegerParameter('4_RfR 0',0,1),\n",
    "                     IntegerParameter('0_RfR 0',0,1),\n",
    "                     IntegerParameter('EWS_DaysToThreat',0,4)]\n",
    "\n",
    "# specify outcomes\n",
    "# note how we need to explicitely indicate the direction\n",
    "dike_model.outcomes = [ScalarOutcome('Expected Annual Damage', kind=ScalarOutcome.MINIMIZE),\n",
    "                  ScalarOutcome('Total Investment Costs', kind=ScalarOutcome.MINIMIZE),\n",
    "                  ScalarOutcome('Expected Number of Deaths', kind=ScalarOutcome.MINIMIZE)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Search for candidate solutions through optimization\n",
    "from ema_workbench.em_framework.optimization import (ArchiveLogger,\n",
    "                                                     EpsilonProgress)\n",
    "convergence_metrics = [\n",
    "    ArchiveLogger(\n",
    "        \"./archives\",\n",
    "        [l.name for l in dike_model.levers],\n",
    "        [o.name for o in dike_model.outcomes],\n",
    "        base_filename=\"test_1.tar.gz\",\n",
    "    ),\n",
    "    EpsilonProgress(),\n",
    "]\n",
    "\n",
    "with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "    results, convergence = evaluator.optimize(nfe=5000, searchover='levers',\n",
    "                                 convergence=convergence_metrics,\n",
    "                                 epsilons=[0.01,]*len(dike_model.outcomes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the code to run the optimization. Results were saved and therefore it is commented out.\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# The Hypervolume space has already been defined in the get_problem_formulation_altered function\n",
    "convergence_metrics = [EpsilonProgress()]\n",
    "\n",
    "nfe = 7500\n",
    "results_deep = []\n",
    "convergence_all = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_runs, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                        epsilons=[0.1,]*len(dike_model.outcomes))\n",
    "                                        \n",
    "        \n",
    "        results_deep.append(results_runs)\n",
    "        convergence_all.append(convergence)\n",
    "\n",
    "# from ema_workbench import save_results\n",
    "\n",
    "# for i in range(len(results_deep)):\n",
    "#     save_results((results_deep[i], convergence_all[i]), f'../results/mordm_7500_rp_scenario{i}.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell contains the code to run the optimization. Results were saved and therefore it is commented out.\n",
    "\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# The Hypervolume space has already been defined in the get_problem_formulation_altered function\n",
    "convergence_metrics = [HyperVolume.from_outcomes(dike_model.outcomes),\n",
    "                       EpsilonProgress()]\n",
    "\n",
    "nfe = 7500\n",
    "results_deep = []\n",
    "convergence_all = []\n",
    "\n",
    "for scenario in scenarios:\n",
    "    with MultiprocessingEvaluator(dike_model) as evaluator:\n",
    "        results_runs, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "                                        epsilons=[1e7, 1e6, 0.00001],\n",
    "                                        convergence=convergence_metrics, reference=scenario)\n",
    "                                        \n",
    "        \n",
    "        results_deep.append(results_runs)\n",
    "        convergence_all.append(convergence)\n",
    "\n",
    "from ema_workbench import save_results\n",
    "\n",
    "for i in range(len(results_deep)):\n",
    "    save_results((results_deep[i], convergence_all[i]), f'../results/mordm_test{i}.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "from ema_workbench.em_framework.optimization import (\n",
    "    ArchiveLogger,\n",
    "    EpsilonProgress,\n",
    "    to_problem,\n",
    "    epsilon_nondominated,\n",
    ")\n",
    "\n",
    "results = []\n",
    "nfes = 100\n",
    "\n",
    "for scenario in scenarios:\n",
    "    convergence_metrics = [\n",
    "                            ArchiveLogger(\n",
    "                                \"./results\",\n",
    "                                [l.name for l in dike_model.levers],\n",
    "                                [o.name for o in dike_model.outcomes],\n",
    "                                base_filename=f\"test_test_{scenario.name}_seed.tar.gz\",\n",
    "                            ),\n",
    "                            EpsilonProgress(),\n",
    "                        ]\n",
    "    epsilons = [0.1,]*len(dike_model.outcomes)\n",
    "    \n",
    "    results.append(optimize(scenario, nfes, dike_model, convergence_metrics, epsilons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "from ema_workbench.em_framework.optimization import (\n",
    "    ArchiveLogger,\n",
    "    EpsilonProgress,\n",
    "    to_problem,\n",
    "    epsilon_nondominated,\n",
    ")\n",
    "\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "def optimize(scenario, nfe, model, epsilons):\n",
    "    results = []\n",
    "    convergences = []\n",
    "    problem = to_problem(model, searchover=\"levers\")\n",
    "\n",
    "    with MultiprocessingEvaluator(model) as evaluator:\n",
    "        convergence_metrics = [\n",
    "            ArchiveLogger(\n",
    "                \"./results\",\n",
    "                [l.name for l in model.levers],\n",
    "                [o.name for o in model.outcomes],\n",
    "                base_filename=f\"test_test_{scenario.name}_seed.tar.gz\",\n",
    "            ),\n",
    "            EpsilonProgress(),\n",
    "        ]\n",
    "\n",
    "        result, convergence = evaluator.optimize(\n",
    "            nfe=nfe,\n",
    "            searchover='levers',\n",
    "            convergence=convergence_metrics,\n",
    "            epsilons=epsilons,\n",
    "            reference=scenario\n",
    "        )\n",
    "\n",
    "        results.append(result)\n",
    "        convergences.append(convergence)\n",
    "\n",
    "    # Merge the results using a non-dominated sort\n",
    "    reference_set = epsilon_nondominated(results, epsilons, problem)\n",
    "\n",
    "    return reference_set, convergences\n",
    "\n",
    "results = []\n",
    "for scenario in scenarios:\n",
    "    epsilons = [0.05] * len(dike_model.outcomes)\n",
    "\n",
    "    # Note that 100000 nfe is rather low to ensure proper convergence\n",
    "    results.append(optimize(scenario, 100, dike_model, epsilons))\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ema_workbench import MultiprocessingEvaluator, ema_logging\n",
    "# from ema_workbench.em_framework.evaluators import BaseEvaluator\n",
    "\n",
    "# from ema_workbench.em_framework.optimization import (ArchiveLogger,\n",
    "#                                                      EpsilonProgress,\n",
    "#                                                      to_problem, epsilon_nondominated)\n",
    "\n",
    "# ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# def optimize(scenario, nfe, model, epsilons):\n",
    "#     results = []\n",
    "#     convergences = []\n",
    "#     problem = to_problem(model, searchover=\"levers\")\n",
    "\n",
    "#     with MultiprocessingEvaluator(model) as evaluator:\n",
    "#         for i in range(5):\n",
    "#             print('for loop begint')\n",
    "#             convergence_metrics = [\n",
    "#                 ArchiveLogger(\n",
    "#                     \"./results\",\n",
    "#                     [l.name for l in model.levers],\n",
    "#                     [o.name for o in model.outcomes],\n",
    "#                     base_filename=f\"test_test_{scenario.name}_seed_{i}.tar.gz\",\n",
    "#                 ),\n",
    "#                 EpsilonProgress(),\n",
    "#             ]\n",
    "\n",
    "#             result, convergence = evaluator.optimize(nfe=nfe, searchover='levers',\n",
    "#                                          convergence=convergence_metrics,\n",
    "#                                          epsilons=epsilons,\n",
    "#                                          reference=scenario)\n",
    "#             print('evaluator.optimize is gerund')\n",
    "#             results.append(result)\n",
    "#             convergences.append(convergence)\n",
    "    \n",
    "#     # merge the results using a non-dominated sort  \n",
    "#     reference_set = epsilon_nondominated(results, epsilons, problem)    \n",
    "            \n",
    "#     return reference_set, convergences\n",
    "\n",
    "\n",
    "# results = []\n",
    "# for scenario in scenarios:\n",
    "#     epsilons = [0.05,]*len(dike_model.outcomes)\n",
    "    \n",
    "#     # note that 100000 nfe is again rather low to ensure proper convergence\n",
    "#     results.append(optimize(scenario, 100, dike_model, epsilons))\n",
    "#     print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
